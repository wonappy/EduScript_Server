# [serivces/language_service.py]
# LLM μ‘μ—… λ΅μ§ μ²λ¦¬
import asyncio 
from src.app.modules.llm.openai_llm import OpenAILLM
from src.app.modules.file.file_data import FileData
from src.app.dto.refinement_dto import SpeechRefineRequest, SpeechRefineResponse
from src.app.prompts.refining_prompt import refine_lecture_prompt, refine_meeting_prompt
from src.app.prompts.summarizing_prompt import summarize_lecture_prompt, summarize_meeting_prompt
from src.app.prompts.keypoints_prompt import extract_keypoints_prompt
from src.app.utils.file_generator_factory import create_file_by_format

api_call_count = 0  # API νΈμ¶ νμ μΉ΄μ΄νΈ

# LLM λ¨λ“ 
llm_module = OpenAILLM() 

# =============================================================================
# λ©”μΈ μ„λΉ„μ¤ ν•¨μ
# =============================================================================

async def build_text_service(request: SpeechRefineRequest) -> SpeechRefineResponse:
    """λ°ν™” μ •μ  ν†µν•© μ„λΉ„μ¤ - λ¨λ“λ³„/νμΌν•μ‹λ³„ μ²λ¦¬"""
    try:
        print("=== [SERVICE] λ°ν™” μ •μ  μ‹μ‘ ===")
        print(f"λ¨λ“: {request.processing_mode}")
        print(f"νμΌν•μ‹: {request.fileFormat}")
        print(f"νμΌλ…: {request.fileName}")
        print(f"μ •μ : {request.enable_refine}, μ”μ•½: {request.enable_summarize}, ν•µμ‹¬: {request.enable_keypoints}")

        # 1λ‹¨κ³„: λ¨λ“λ³„ κΈ°λ³Έ μ •μ 
        refined_text = await _refine_by_mode(request.full_text, request.processing_mode)
        print(f"β… κΈ°λ³Έ μ •μ  μ™„λ£")

        # 2λ‹¨κ³„: νμΌ μƒμ„±
        if request.processing_mode == "lecture":
            return await _process_lecture_mode(request, refined_text)
        elif request.processing_mode == "conference":
            return await _process_conference_mode(request, refined_text)
        else:
            raise Exception(f"μ§€μ›ν•μ§€ μ•λ” λ¨λ“: {request.processing_mode}")
    
    except Exception as e:
        print(f"β μ„λΉ„μ¤ μ¤λ¥: {str(e)}")
        raise Exception(f"[SERVICE ERROR] λ°ν™” μ •μ  μ‹¤ν¨ - {str(e)}")

# =============================================================================
# λ¨λ“λ³„ μ²λ¦¬ ν•¨μ
# =============================================================================

async def _process_lecture_mode(request: SpeechRefineRequest, refined_text: str) -> SpeechRefineResponse:
    """κ°•μ λ¨λ“ μ²λ¦¬: μ •μ  + μ”μ•½ + ν•µμ‹¬ν¬μΈνΈ"""
    print("π“ κ°•μ λ¨λ“ μ²λ¦¬ μ‹μ‘")
    
    refined_result = None
    summarized_result = None
    keypoints_result = None

    # μ •μ λ νμΌ
    if request.enable_refine:
        refined_result = create_file_by_format(
            content=refined_text,
            filename=f"{request.fileName}_μ •μ λλ‚΄μ©",
            file_format=request.fileFormat,
        )
        print("β… μ •μ  νμΌ μƒμ„± μ™„λ£")

    # μ”μ•½ νμΌ
    if request.enable_summarize:
        summarized_text = await _summarize_lecture_text(refined_text)
        summarized_result = create_file_by_format(
            content=summarized_text,
            filename=f"{request.fileName}_μ”μ•½",
            file_format=request.fileFormat,
        )
        print("β… μ”μ•½ νμΌ μƒμ„± μ™„λ£")

    # ν•µμ‹¬ν¬μΈνΈ νμΌ
    if request.enable_keypoints:
        keypoints_text = await _extract_lecture_keypoints(refined_text)
        keypoints_result = create_file_by_format(
            content=keypoints_text,
            filename=f"{request.fileName}_ν•µμ‹¬ν¬μΈνΈ",
            file_format=request.fileFormat,
        )
        print("β… ν•µμ‹¬ν¬μΈνΈ νμΌ μƒμ„± μ™„λ£")

    return _create_response(refined_result, summarized_result, keypoints_result)

async def _process_conference_mode(request: SpeechRefineRequest, refined_text: str) -> SpeechRefineResponse:
    """νμ λ¨λ“ μ²λ¦¬: νμλ΅ κµ¬μ΅°ν™”"""
    print("π¤ νμ λ¨λ“ μ²λ¦¬ μ‹μ‘")
    print(f"νμΌ ν•μ‹ : {request.fileFormat}")
    
    refined_result = None
    summarized_result = None

    # μ •μ λ νμΌ
    if request.enable_refine:
        refined_result = create_file_by_format(
            content=refined_text,
            filename=f"{request.fileName}_μ •μ λλ‚΄μ©",
            file_format=request.fileFormat,
        )
        print("β… μ •μ  νμΌ μƒμ„± μ™„λ£")

        # μ”μ•½ νμΌ
    if request.enable_summarize:
        summarized_text = await _summarize_meeting_text(refined_text)
        summarized_result = create_file_by_format(
            content=summarized_text,
            filename=f"{request.fileName}_μ”μ•½",
            file_format=request.fileFormat,
        )
        print("β… μ”μ•½ νμΌ μƒμ„± μ™„λ£")

    return _create_response(refined_result, summarized_result, None)

# =============================================================================
# LLM μ²λ¦¬ ν•¨μλ“¤
# =============================================================================

#κ°•μ/νμλ³„ μ •μ  ν”„λ΅¬ν”„νΈ κµ¬λ¶„ -> llm μ •μ  μ²λ¦¬
async def _refine_by_mode(text: str, mode: str) -> str:
    """λ¨λ“λ³„ κΈ°λ³Έ μ •μ """
    if mode == "conference":
        prompt = refine_meeting_prompt()
        print("π¤ νμμ© μ •μ  ν”„λ΅¬ν”„νΈ μ‚¬μ©")
    else:  # lecture
        prompt = refine_lecture_prompt()
        print("π“ κ°•μμ© μ •μ  ν”„λ΅¬ν”„νΈ μ‚¬μ©")
    
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": text}
    ]
    
    return await llm_module.select_gpt_model(messages=messages)

async def _summarize_lecture_text(text: str) -> str:
    """ν…μ¤νΈ μ”μ•½"""
    print("π“ ν…μ¤νΈ μ”μ•½ μ¤‘...")
    
    messages = [
        {"role": "system", "content": summarize_lecture_prompt()},
        {"role": "user", "content": text}
    ]
    
    return await llm_module.select_gpt_model(messages=messages)

async def _summarize_meeting_text(text: str) -> str:
    """ν…μ¤νΈ μ”μ•½"""
    print("π“ ν…μ¤νΈ μ”μ•½ μ¤‘...")
    
    messages = [
        {"role": "system", "content": summarize_meeting_prompt()},
        {"role": "user", "content": text}
    ]
    
    return await llm_module.select_gpt_model(messages=messages)

async def _extract_lecture_keypoints(text: str) -> str:
    """ν•µμ‹¬ ν¬μΈνΈ μ¶”μ¶"""
    print("π― ν•µμ‹¬ ν¬μΈνΈ μ¶”μ¶ μ¤‘...")
    
    messages = [
        {"role": "system", "content": extract_keypoints_prompt()},
        {"role": "user", "content": text}
    ]
    
    return await llm_module.select_gpt_model(messages=messages)

def _create_response(refined_result: FileData = None, 
                    summarized_result: FileData = None, 
                    keypoints_result: FileData = None) -> SpeechRefineResponse:
    """μ‘λ‹µ κ°μ²΄ μƒμ„±"""
    total_files = sum(1 for result in [refined_result, summarized_result, keypoints_result] if result is not None)
    
    response = SpeechRefineResponse(
        refined_result=refined_result,
        summarized_result=summarized_result,
        keypoints_result=keypoints_result,
        total_files=total_files,
        message=f"β… μ΄ {total_files}κ° νμΌμ΄ μƒμ„±λμ—μµλ‹λ‹¤." if total_files > 0 else "β νμΌ μƒμ„±μ— μ‹¤ν¨ν–μµλ‹λ‹¤."
    )
    print(f"μ²λ¦¬ μ™„λ£ - μƒμ„±λ νμΌ: {total_files}κ°")
    return response