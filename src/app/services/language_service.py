# [serivces/language_service.py]
# LLM ì‘ì—… ë¡œì§ ì²˜ë¦¬ 
from fastapi import HTTPException
import logging
from src.app.modules.llm.openai_llm import OpenAILLM
from src.app.dto.refinement_dto import SpeechRefineRequest, SpeechSummarizeRequest, KeyPointsExtractRequest, SpeechRefineResponse, SpeechSummarizeResponse, KeyPointsExtractResponse
from src.app.prompts.refining_prompt import refine_speech_prompt
from src.app.prompts.summarizing_prompt import summarize_speech_prompt
from src.app.prompts.keypoints_prompt import extract_keypoints_prompt

# [0] LLM ëª¨ë“ˆ 
llm_module = OpenAILLM() 

# [1] ë°œí™” ì •ì œ
async def refine_speech_service(request: SpeechRefineRequest) -> SpeechRefineResponse:
    try:
        # ğŸ”´ ë””ë²„ê¹…
        print(f"=== [SERVICE DEBUG 1] refine_speech_service ===") 
        print(f"[SERVICE] full_speech: {request.full_speech if hasattr(request, 'full_speech') else 'None'}")
        
        # 1) í”„ë¡¬í”„íŠ¸ ì„¤ê³„
        messages = [
            { "role": "system", "content": refine_speech_prompt() },
            { "role": "user", "content": f" ë‹¤ìŒ ë°œí™”ë¥¼ ì •ì œí•´ì£¼ì„¸ìš” : {request.full_speech}" } 
         ]        
        # 2) LLM ëª¨ë“ˆ í˜¸ì¶œ 
        refined_text = await llm_module.select_gpt_model(messages=messages)        
        # 3) ì‘ë‹µ DTO 
        return SpeechRefineResponse(refined_speech=refined_text)
    except HTTPException as e:
        logging.error(f"[SERVICE ERROR] ë°œí™” ì •ì œ HTTP ì—ëŸ¬ ë°œìƒ - [{e.status_code}: {e.detail}]")
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"[SERVICE ERROR] ë°œí™” ì •ì œ ì‹¤íŒ¨ - {str(e)}")

# [2] ë°œí™” ìš”ì•½
async def summarize_speech_service(request: SpeechSummarizeRequest) -> SpeechSummarizeResponse:
    try:
        # ğŸ”´ ë””ë²„ê¹…
        print(f"=== [SERVICE DEBUG 2] summarize_speech_service ===") 
        print(f"[SERVICE] refined_speech: {request.refined_speech if hasattr(request, 'refined_speech') else 'None'}")
        
        # 1) í”„ë¡¬í”„íŠ¸ ì„¤ê³„
        messages = [
            { "role": "system", "content": summarize_speech_prompt() },
            { "role": "user", "content": f"ë‹¤ìŒ ë°œí™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš” : {request.refined_speech}" }
        ]
        # 2) LLM ëª¨ë“ˆ í˜¸ì¶œ 
        summarized_text = await llm_module.select_gpt_model(messages=messages)
        # 3) ì‘ë‹µ DTO
        return SpeechSummarizeResponse(summarized_speech=summarized_text)
    except HTTPException as e:
        logging.error(f"[SERVICE ERROR] ë°œí™” ìš”ì•½ HTTP ì—ëŸ¬ ë°œìƒ - [{e.status_code}: {e.detail}]")
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"[SERIVCE ERROR] ë°œí™” ìš”ì•½ ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")

# [3] ì¤‘ìš” ë‚´ìš© ì¶”ì¶œ
async def extract_keypoints_service(request: KeyPointsExtractRequest) -> KeyPointsExtractResponse:
    try:
        # ğŸ”´ ë””ë²„ê¹…
        print(f"=== [SERVICE DEBUG 3] extract_keypoints_service ===") 
        print(f"[SERVICE] refined_speech: {request.refined_speech if hasattr(request, 'refined_speech') else 'None'}")

        # 1) í”„ë¡¬í”„íŠ¸ ì„¤ê³„
        messages = [
            { "role": "system", "content": extract_keypoints_prompt() },
            { "role": "user", "content": f"ë‹¤ìŒ ë°œí™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš” : {request.refined_speech}" }
        ]
        # 2) LLM ëª¨ë“ˆ í˜¸ì¶œ 
        extracted_text = await llm_module.select_gpt_model(messages=messages)
        # 3) ì‘ë‹µ DTO
        return KeyPointsExtractResponse(extracted_keypoints=extracted_text)
    except HTTPException as e:
        logging.error(f"[SERVICE ERROR] ë°œí™” ìš”ì•½ HTTP ì—ëŸ¬ ë°œìƒ - [{e.status_code}: {e.detail}]")
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"[SERIVCE ERROR] ë°œí™” ìš”ì•½ ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")