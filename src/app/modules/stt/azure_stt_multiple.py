# [modules/stt/azure_stt_multiple.py]
# Azure Speech to Text AI
import os
import azure.cognitiveservices.speech as speechsdk
import asyncio  #async ì„ ì–¸ì´ ì•ˆëœ ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ë•Œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

class AzureSTTMultiple:
    # [1] ì´ˆê¸°í™”
    def __init__(self):
        # stt ë³€ìˆ˜ ì´ˆê¸°í™”
        self.azure_key = os.environ['AZURE_STT_KEY']
        self.azure_region = os.environ['AZURE_REGION']  
        # Continuous LID -> v2ì—”ë“œí¬ì¸íŠ¸ ê¶Œì¥
        self.speech_v2_endpoint = f"wss://{self.azure_region}.stt.speech.microsoft.com/speech/universal/v2"
        self.speech_recognizer = None
        self.audio_stream = None
        self.is_listening = False   # ìŒì„± ì¸ì‹ ì¤‘ë³µ ë°©ì§€
        self.result_queue = None    # stt ê²°ê³¼ ì €ì¥ í•¨ìˆ˜ ["language", "text"] (ë™ê¸° ì €ì¥ -> ë¹„ë™ê¸° ì¶”ì¶œ)

    # [2] ìŒì„± ì¸ì‹ ì„¤ì •
    def setup_streaming_recognition(self, input_languages: list[str]) : 
        """
        ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìŒì„± ì¸ì‹ ì„¤ì •
        input_language : ì…ë ¥ ì–¸ì–´ ì½”ë“œ
        """

        # stt ê²°ê³¼ ì €ì¥ queue ìƒì„±
        if self.result_queue is None:
            self.result_queue = asyncio.Queue()

        #speech ì„¤ì •
        speech_config = speechsdk.SpeechConfig(
            subscription=self.azure_key,
            endpoint=self.speech_v2_endpoint,
        )
        
        speech_config.set_property(speechsdk.PropertyId.Speech_SegmentationSilenceTimeoutMs, "300")               # ë” ë¹ ë¥¸ êµ¬ê°„ ì¸ì‹
        speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, "1000")  # ì´ˆê¸° ì¹¨ë¬µ ì‹œê°„ ë‹¨ì¶•
        speech_config.set_property(property_id=speechsdk.PropertyId.SpeechServiceConnection_LanguageIdMode, value='Continuous')     # ë‹¤ì¤‘ ì–¸ì–´ ì¸ì‹ ëª¨ë“œ
        speech_config.set_property_by_name("SpeechServiceConnection_RecoMode", "CONVERSATION")
        speech_config.enable_dictation() 

        #ì¸ì‹ ì–¸ì–´ ì„¤ì • (ìµœì†Œ 1ê°œ ~ ìµœëŒ€ 10ê°œ)
        #ë™ì¼í•œ ì–¸ì–´ì— ëŒ€í•´ ì—¬ëŸ¬ ë¡œìº˜ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”(ì˜ˆ: en-USë° en-GB)
        auto_detect_source_language_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(languages=input_languages)

        #ì˜¤ë””ì˜¤ ì„¤ì •
        audio_format = speechsdk.audio.AudioStreamFormat(
            samples_per_second=16000, 
            bits_per_sample=16, 
            channels=1
        )
        self.audio_stream = speechsdk.audio.PushAudioInputStream(audio_format)
        audio_config = speechsdk.audio.AudioConfig(stream=self.audio_stream)

        # ìŒì„± ì¸ì‹ê¸° ìƒì„±
        self.speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config,
            auto_detect_source_language_config=auto_detect_source_language_config,
            audio_config=audio_config
        )

        # # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        # # mode - recognized : sttê°€ í•œ ë¬¸ì¥ ì¸ì‹ì„ ì™„ë£Œí–ˆì„ ë•Œì˜ ê²°ê³¼ê°’ì„ ë°˜í™˜. ì‹¤ì‹œê°„ì„±ì€ ë–¨ì–´ì§€ì§€ë§Œ í’ˆì§ˆì´ ìš°ìˆ˜.
        # def recognized_handler(evt):            
        #     if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:    #stt ê²°ê³¼ ë°›ì•„ì˜¤ê¸° -> ì²˜ë¦¬ ìì²´ë¥¼ ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì§„í–‰ (ë¹„ë™ê¸° í•¨ìˆ˜ ì‚¬ìš©x)
        #         text = evt.result.text.strip()

        #         #ì¸ì‹ ìŒì„± ë¶„ì„
        #         auto_detect_result = speechsdk.AutoDetectSourceLanguageResult(evt.result)
        #         detected_language = auto_detect_result.language

        #         if text:
        #             print(f"ğŸ—£ï¸ ì›ë³¸: {text}\n")
        #             try:
        #                 result_data = {
        #                     'language': detected_language,
        #                     'text': text
        #                 }
        #                 self.result_queue.put_nowait(result_data)                      #ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë°˜í™˜ëœ stt ê²°ê³¼ë¥¼ queueì— ìˆœì„œëŒ€ë¡œ ì €ì¥
        #             except Exception as e:
        #                 print(f"í ì¶”ê°€ ì˜¤ë¥˜: {e}")
        #         else:
        #             print("ğŸ”‡ ë¹ˆ í…ìŠ¤íŠ¸ ê²°ê³¼")
        #     elif evt.result.reason == speechsdk.ResultReason.NoMatch:
        #         print("ğŸ”‡ ìŒì„± ì¸ì‹ ê²°ê³¼ ì—†ìŒ")
        #     else:
        #         print(f"ğŸ” ê¸°íƒ€ STT ê²°ê³¼: {evt.result.reason}")

        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì • - recognizing
        # mode - recognizing : sttê°€ ì¸ì‹í•œ ë‹¨ìœ„ì˜ ì—°ì†í•´ì„œ ë°˜í™˜. ì‹¤ì‹œì„±ì´ ìš°ìˆ˜í•˜ë‚˜ ë¹ ë¥¸ ì—…ë°ì´íŠ¸ë¡œ ë³´ê¸° ì–´ì§€ëŸ¬ìš¸ ìˆ˜ ìˆìŒ.
        def recognizing_handler(evt):            
            if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:    #stt ê²°ê³¼ ë°›ì•„ì˜¤ê¸° -> ì²˜ë¦¬ ìì²´ë¥¼ ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì§„í–‰ (ë¹„ë™ê¸° í•¨ìˆ˜ ì‚¬ìš©x)
                text = evt.result.text.strip()

                #ì¸ì‹ ìŒì„± ë¶„ì„
                auto_detect_result = speechsdk.AutoDetectSourceLanguageResult(evt.result)
                detected_language = auto_detect_result.language

                if text:
                    print(f"ğŸ—£ï¸ ì›ë³¸: {text} (ì–¸ì–´ : {detected_language})\n")
                    try:
                        result_data = {
                            'language': detected_language,
                            'text': text
                        }
                        self.result_queue.put_nowait(result_data)    #ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë°˜í™˜ëœ stt ê²°ê³¼ë¥¼ queueì— ìˆœì„œëŒ€ë¡œ ì €ì¥
                    except Exception as e:
                        print(f"í ì¶”ê°€ ì˜¤ë¥˜: {e}")
                else:
                    print("ğŸ”‡ ë¹ˆ í…ìŠ¤íŠ¸ ê²°ê³¼")
            elif evt.result.reason == speechsdk.ResultReason.NoMatch:
                print("ğŸ”‡ ìŒì„± ì¸ì‹ ê²°ê³¼ ì—†ìŒ")
            else:
                print(f"ğŸ” ê¸°íƒ€ STT ê²°ê³¼: {evt.result.reason}")


        # ê³µí†µ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ ì •ì˜ - reconizing + recognized
        def hybrid_result_handler(evt, is_final: bool):
            reason = evt.result.reason
            
            if reason == speechsdk.ResultReason.RecognizingSpeech or reason == speechsdk.ResultReason.RecognizedSpeech:
                text = evt.result.text.strip()

                #ìŒì„± ì¸ì‹ ë¶„ì„
                auto_detect_result = speechsdk.AutoDetectSourceLanguageResult(evt.result)
                detected_language = auto_detect_result.language

                if text:
                    result_data = {
                        'language': detected_language,
                        'text': text,
                        'is_final': is_final
                    }
                    print(f"ğŸ—£ï¸  {'[ìµœì¢…]' if is_final else '[ì¤‘ê°„]'} {text} (ì–¸ì–´ : {detected_language})")
                    try:
                        self.result_queue.put_nowait(result_data)   #ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë°˜í™˜ëœ stt ê²°ê³¼ë¥¼ queueì— ìˆœì„œëŒ€ë¡œ ì €ì¥
                    except Exception as e:
                        print(f"í ì¶”ê°€ ì˜¤ë¥˜: {e}")
            
            elif reason == speechsdk.ResultReason.NoMatch:
                print("ğŸ”‡ ìŒì„± ì¸ì‹ ê²°ê³¼ ì—†ìŒ (NoMatch)")

        def session_started_handler(evt):
            print("ğŸ¯ ìŒì„± ì¸ì‹ ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        def session_stopped_handler(evt):
            print("ğŸ›‘ ìŒì„± ì¸ì‹ ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.is_listening = False
            
        def canceled_handler(evt):
            print(f"âŒ ìŒì„± ì¸ì‹ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤: {evt.result.cancellation_details.reason}")
            if evt.result.cancellation_details.reason == speechsdk.CancellationReason.Error:
                print(f"ì˜¤ë¥˜ ì„¸ë¶€ì‚¬í•­: {evt.result.cancellation_details.error_details}")
            self.is_listening = False
        
        # ì´ë²¤íŠ¸ ì—°ê²°
        # stt ê²°ê³¼ê°€ ë‚˜ì™”ì„ ë•Œ,
        self.speech_recognizer.recognized.connect(lambda evt: hybrid_result_handler(evt, is_final=True))                   
        self.speech_recognizer.recognizing.connect(lambda evt: hybrid_result_handler(evt, is_final=False))

        self.speech_recognizer.session_started.connect(session_started_handler)         # ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆì„ ë•Œ, 
        self.speech_recognizer.session_stopped.connect(session_stopped_handler)         # ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆì„ ë•Œ,
        self.speech_recognizer.canceled.connect(canceled_handler)                       # ì¸ì‹ì´ ì·¨ì†Œë˜ì—ˆì„ ë–„,
    
    # [3] ìŒì„± ì¸ì‹ 
    def start_recognition(self):
        """ì—°ì† ìŒì„± ì¸ì‹ ì‹œì‘"""
        
        # ì¤‘ë³µ ì¸ì‹ ë°©ì§€
        if self.is_listening:
            print("âš ï¸ ì´ë¯¸ ìŒì„± ì¸ì‹ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return
        
        # ì—°ì† ì¸ì‹ ì‹œì‘
        self.speech_recognizer.start_continuous_recognition()   ## Azure STT audio_stream ëª¨ë‹ˆí„°ë§ ì‹œì‘ -> audio_data ì¶”ê°€ë˜ëŠ” ê²ƒ ì¸ì‹
        self.is_listening = True

    # [3-1] ì‹¤ì‹œê°„ ìŒì„± ë°›ì•„ì˜¤ê¸° : audio_streamì— ë°ì´í„° ì¶”ê°€ â†’ Azureê°€ ìë™ ê°ì§€ â†’ STT ì²˜ë¦¬ â†’ ì½œë°± í˜¸ì¶œ
    def write_audio_chunk(self, audio_data: bytes):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ìŠ¤íŠ¸ë¦¼ì— ì¶”ê°€
        
        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        """
        if self.audio_stream and self.is_listening:
            self.audio_stream.write(audio_data)
            print(f"Azure STTì— ì˜¤ë””ì˜¤ ì „ì†¡: {len(audio_data)} bytes")
        else:
            print(f"Azure STT ë¹„í™œì„± ìƒíƒœ: stream={self.audio_stream is not None}, listening={self.is_listening}")
    
    # [3-2] ìŒì„± ì²˜ë¦¬ ê²°ê³¼ queue ë¹„ë™ê¸°ë¡œ ë°˜í™˜
    async def get_recognition_result(self):
        """STT ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ë¡œ ë°˜í™˜"""
        try:
            return await self.result_queue.get()
        except:
            return None

    # [4] ì‹¤í–‰ ì¤‘ì§€
    def stop_recognition(self):
        """ì—°ì† ìŒì„± ì¸ì‹ ì¤‘ì§€"""
        if self.speech_recognizer and self.is_listening:
            print("\nğŸ›‘ ìŒì„± ì¸ì‹ì„ ì¤‘ì§€í•©ë‹ˆë‹¤...")
            self.speech_recognizer.stop_continuous_recognition()
            self.is_listening = False
        else:
            print("âš ï¸ ì§„í–‰ ì¤‘ì¸ ìŒì„± ì¸ì‹ì´ ì—†ìŠµë‹ˆë‹¤.")

        if self.audio_stream:
            self.audio_stream.close()
            self.audio_stream = None

        print("âœ… ìŒì„± ì¸ì‹ ì¤‘ì§€ ì™„ë£Œ")

    # [5] ìŒì„± ì¸ì‹ ì–¸ì–´ ë³€ê²½
    def change_setup_recognition(self, input_language) : 
        self.stop_recognition()                                     # ê¸°ì¡´ ì¸ì‹ ì¤‘ì§€
        self.setup_streaming_recognition(input_language)  # ìŒì„± ì¸ì‹ ì–¸ì–´ ë³€ê²½
        self.start_recognition()                                    # ë‹¤ì‹œ ì‹œì‘

    def is_active(self) -> bool:
        """í˜„ì¬ ì¸ì‹ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        return self.is_listening