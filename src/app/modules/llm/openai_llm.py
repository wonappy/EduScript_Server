#[modules/llm/openai_llm.py]
# LLM API Key í˜¸ì¶œ 
import openai
from openai import AsyncOpenAI
from src.app.core.config import api_settings

class OpenAILLM:
    # [1] ì´ˆê¸°í™” - OpenAI API í‚¤ í˜¸ì¶œ 
    def __init__(self):        
        # print(f"API í‚¤ í™•ì¸: {api_settings.openai_llm_key[:10]}...") # ğŸ”´ ë””ë²„ê¹…
        self.client = AsyncOpenAI(
            api_key=api_settings.openai_llm_key
        )

    # [2] LLM ëª¨ë¸ í˜¸ì¶œ - í…ìŠ¤íŠ¸ ìƒì„± ë° ë°˜í™˜
    async def select_gpt_model(self, messages: list, temperature: float = 0.3) -> str:
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini", # ğŸ”´ Chat GPT ëª¨ë¸ 
                messages=messages,
                temperature=temperature
            )
            return response.choices[0].message.content # choices[0] : contentë§Œ ë°˜í™˜
        
        except openai.AuthenticationError as e:
            raise Exception(f"[MODULE ERROR] API í‚¤ ì¸ì¦ ì‹¤íŒ¨ - {str(e)}")
        except openai.RateLimitError as e:
            raise Exception(f"[MODULE ERROR] API í˜¸ì¶œ ì œí•œ ì´ˆê³¼ - {str(e)}")
        except openai.APIConnectionError as e:
            raise Exception(f"[MODULE ERROR] API ì—°ê²° ì‹¤íŒ¨ - {str(e)}") # ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ
        except openai.BadRequestError as e:
            raise Exception(f"[MODULE ERROR] ì˜ëª»ëœ ìš”ì²­ - {str(e)}") # ë¹ˆ ë©”ì‹œì§€ or ì˜ëª»ëœ íŒŒë¼ë¯¸í„°
        except Exception as e:
            raise Exception(f"[MODULE ERROR] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ - {str(e)}")
        openai_llm.py